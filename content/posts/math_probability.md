---
author: "KnightSnape"
title: "Math Probability"
date: "2024-1-22"
description: "The total result of math probabilitys"
tags: ["math"]
aliases: ["migrate-from-jekyl"]
ShowToc: true
TocOpen: true
weight: 2
---

# 概率论

* [1.贝叶斯公式](#1-贝叶斯公式)

* [2.随机变量](#2-随机变量)

    * [2.1.随机变量](#21-随机变量)

    * [2.2.随机变量的期望与方差](#22-随机变量的期望与方差)

    * [2.3.概率密度函数](#23-概率密度函数)

* [3.离散随机变量分布](#3-离散随机变量分布)

    * [3.1.二项分布](#31-二项分布)

    * [3.2.几何分布](#32-几何分布)

    * [3.3.泊松分布](#33-泊松分布)

    * [3.4.超几何分布](#34-超几何分布)

    * [3.5.负二项分布](#35-负二项分布)

* [4.连续随机变量分布](#4-连续随机变量分布)

    * [4.1.连续型均匀分布](#41-连续型均匀分布)

    * [4.2.指数分布](#42-指数分布)

    * [4.3.正态分布](#43-正态分布)

    * [4.4.卡方分布](#44-卡方分布)




# 1.贝叶斯公式

一位参观者将来到西交利物浦大学参加研讨会。他来的概率
火车、汽车和航班分别为0.5、0.3和0.2。以及延迟的可能性
这三种运输方式分别是0.1、0.3和0.4。如果访客
研讨会迟到了，那么他是乘坐火车的概率是多少？

可以使用贝叶斯公式来计算参观者是乘坐火车的概率，假设事件C表示参观者迟到，事件T表示参观者乘坐火车。

根据全概率公式，可以计算参观者迟到的概率：

P(C) = P(C|T) * P(T) + P(C|not T) * P(not T)

其中，P(C|T)表示在参观者乘坐火车的情况下他迟到的概率，P(C|not T)表示在参观者不乘坐火车的情况下他迟到的概率，P(T)表示参观者乘坐火车的概率，P(not T)表示参观者不乘坐火车的概率。

根据题目中的条件，可以得到：

P(T) = 0.5
P(not T) = 0.5
P(C|T) = 0.1
P(C|not T) = 0.3

将这些值带入上面的公式，可以得到：

P(C) = 0.1 * 0.5 + 0.3 * 0.5
P(C) = 0.2

参观者迟到的概率是0.2。

现在使用贝叶斯公式计算参观者是乘坐火车的概率：

P(T|C) = P(C|T) * P(T) / P(C)

将上面计算的结果代入公式，可以得到：

P(T|C) = 0.1 * 0.5 / 0.2
P(T|C) = 0.25

因此，参观者是乘坐火车的概率是0.25，即有25%的概率参观者是乘坐火车的。

贝叶斯公式的通项公式如下：

$$ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} $$

其中，$P(A|B)$表示在已知事件B发生的情况下事件A发生的概率，称为后验概率；$P(B|A)$表示在已知事件A发生的情况下事件B发生的概率，称为似然概率；$P(A)$表示事件A发生的概率，称为先验概率；$P(B)$表示事件B发生的概率，称为边缘概率。

先验概率是在考虑新证据前我们对事件概率的预先估计。在贝叶斯公式中，我们需要用先验概率作为起点，并将其与新的证据相结合来计算后验概率。

后验概率是在考虑了新证据后，我们对事件概率的更新。在贝叶斯公式中，我们使用先验概率和新的证据来计算后验概率，从而更新我们对事件概率的认识。

似然概率是指在给定某一事件发生的前提下，观察到某种证据的概率。在贝叶斯公式中，似然概率用于描述新证据对事件概率的影响，是根据我们已知的条件和经验来推断事件发生的概率。

如果是一序列的事件，可以使用贝叶斯定理的条件概率的链式法则（Chain Rule of Conditional Probability）来表示，该法则是贝叶斯定理的自然推论。

具体来说，对于一序列的事件 $E_1, E_2, ..., E_n$ 和任意事件 $H$，贝叶斯公式可以表示为：

$$ P(E_n | E_1, E_2, ..., E_{n-1}, H) = \frac{P(H | E_1, E_2, ..., E_{n-1}, E_n) \cdot P(E_n | E_1, E_2, ..., E_{n-1})}{P(H | E_1, E_2, ..., E_{n-1})} $$

其中，$P(E_n | E_1, E_2, ..., E_{n-1}, H)$表示在已知前面 $n-1$ 个事件和证据 $H$ 的情况下，事件 $E_n$ 发生的概率；$P(H | E_1, E_2, ..., E_{n-1}, E_n)$表示在已知所有 $n$ 个事件的情况下，证据 $H$ 发生的概率；$P(E_n | E_1, E_2, ..., E_{n-1})$表示在已知前面 $n-1$ 个事件的情况下，事件 $E_n$ 发生的概率；$P(H | E_1, E_2, ..., E_{n-1})$表示在已知前面 $n-1$ 个事件的情况下，证据 $H$ 发生的概率。

通过不断地应用上述公式，可以得到：

$$ P(E_n | E_1, E_2, ..., E_{n-1}, H) = \frac{P(H | E_n, E_{n-1}, ..., E_1) \cdot P(E_n | E_{n-1}, ..., E_1)}{P(H | E_{n-1}, ..., E_1)} $$

这个公式表示在已知前面 $n-1$ 个事件的情况下，事件 $E_n$ 发生的概率，其中后验概率是通过前面的先验概率和新证据来计算的。

# 2.随机变量

## 2.1.随机变量

在概率论中，随机变量是一个变量，它的取值是由随机事件所决定的，其取值不确定，但其取值的范围和概率分布是已知的。

数学上，随机变量可以定义为一个函数 $X: \Omega \rightarrow \mathbb{R}$，它将样本空间 $\Omega$ 中的每一个元素 $\omega$ 映射到一个实数 $X(\omega)$。随机变量 $X$ 的取值 $x$ 是 $\Omega$ 中使得 $X(\omega)=x$ 的所有 $\omega$ 的集合，通常用 $P(X=x)$ 表示该集合的概率。

随机变量具有以下性质：

它的取值是不确定的，但其取值范围和概率分布是已知的；
它可以是离散的或连续的；
对于任意实数 $x$，$P(X=x) \geq 0$；
对于所有的 $x$，$\sum_{i} P(X=x_i) = 1$ 或 $\int_{-\infty}^{\infty} f(x) dx = 1$；
对于任意函数 $g(x)$，我们可以定义一个新的随机变量 $Y = g(X)$，$Y$ 的概率分布可以通过 $X$ 的概率分布和 $g(x)$ 的函数关系来计算。

## 2.2.离散随机变量的期望和方差

对于一维离散随机变量 $X$，假设它的取值为 $x_1, x_2, ..., x_n$，概率分布为 $P(X=x_1), P(X=x_2), ..., P(X=x_n)$。

则 $X$ 的期望（Expected Value，简称 EV）定义为：

$$ E(X) = \sum_{i=1}^{n} x_i P(X=x_i) $$

即 $X$ 的每个可能取值与其对应的概率的乘积之和。

而 $X$ 的方差（Variance）定义为：

$$ Var(X) = E[(X - E(X))^2] = E(X^2) - [E(X)]^2 $$

其中，$E(X^2)$ 表示 $X^2$ 的期望。

期望和方差之间的关系为：

$$ Var(X) = E(X^2) - [E(X)]^2 $$

$$ \Rightarrow E(X^2) = Var(X) + [E(X)]^2 $$

即 $X$ 的期望的平方加上 $X$ 的方差等于 $X^2$ 的期望。


## 2.3.概率密度函数

概率密度函数是描述连续随机变量概率分布的函数。它可以用来计算连续随机变量落在某个区间内的概率。

概率密度函数 $f(x)$ 定义为在 $x$ 处的导数，即：

$$f(x) = \frac{dF(x)}{dx}$$

其中 $F(x)$ 表示连续随机变量 $X$ 的分布函数（Cumulative Distribution Function，简称 CDF），它是在 $(-\infty, x]$ 区间内 $X$ 取值的概率。概率密度函数可以理解为分布函数的斜率，它在 $x$ 处的值并不表示概率，而是表示在 $x$ 处单位区间内随机变量 $X$ 取值的可能性大小。

概率密度函数需要满足以下两个性质：

$f(x) \geq 0$，即概率密度函数的值非负；
$\int_{-\infty}^{\infty} f(x) dx = 1$，即概率密度函数在整个定义域内的积分等于1，因为连续随机变量在定义域内取值的总概率为1。
在实际应用中，我们可以使用概率密度函数来计算某个区间内连续随机变量的概率，即：

$$ P(a \leq X \leq b) = \int_a^b f(x) dx $$

其中 $a$ 和 $b$ 分别为区间的下限和上限。


# 3.离散随机变量分布

## 3.1.二项分布

二项分布（Binomial distribution）是一种离散概率分布，描述了在一系列独立重复的伯努利试验中成功次数的概率分布。其中每次试验有两个可能结果：成功或失败。该分布的参数是试验次数 n 和成功概率 p。

二项分布的概率质量函数（PMF）如下：

$$P(X=k) = \binom{n}{k}p^k(1-p)^{n-k}$$

其中，$X$ 表示成功次数，$k$ 表示成功的次数，$\binom{n}{k}$ 表示从 $n$ 次试验中取出 $k$ 次成功的组合数，$p$ 表示每次试验成功的概率，$(1-p)$ 表示每次试验失败的概率。

二项分布的性质如下：

期望值：$E(X) = np$
方差：$Var(X) = np(1-p)$

二项分布适用于以下场景：

在一组独立重复的试验中，每次试验有两种可能的结果：成功或失败。
每次试验的成功概率都是相同的，记为 p，失败概率为 1-p。
每次试验都是独立的，即每次试验的结果不受之前试验的结果影响。
感兴趣的是在 n 次试验中成功的次数，而不是成功的概率或失败的概率。
举例来说，以下场景符合二项分布：

投掷硬币 n 次，每次出现正面的概率为 p，求出现正面的次数。
一家医院每天接收 n 名新生儿，每个新生儿患有某种疾病的概率为 p，求每天患病婴儿的数量。
一家电商网站每天进行 n 次广告投放，每次投放被用户点击的概率为 p，求每天被点击的广告数量。

二项分布的期望推导如下：

$$E = \sum_{k=0}^{n}{k\binom{n}{k}p^k(1-p)^{n-k}} \\
    \quad \quad \quad= \sum_{k=1}^{n}\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k} \\
    \quad \quad \quad \quad \quad \ \ = \sum_{k=1}^{n}{\frac{n!}{(k-1)!(n-k)!}p^k(1-p)^{n-k}}  \\
    \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \ \
    = np\sum_{j=0}^{n-1}\binom{n-1}{j}p^j(1-p)^{n-1-j} \quad let j = k - 1 \\
    \quad 
    = np\sum_{j=0}^{n-1}P(X=j) = np$$


## 3.2.几何分布

几何分布是描述独立重复试验中第一次成功所需的试验次数的离散概率分布。通俗地说，它描述了在进行一系列独立重复试验中，第一次成功需要尝试的次数的概率分布。例如，某人射箭，每次射中目标的概率为$p$，那么第一次命中目标的射击次数就符合几何分布。

几何分布的概率质量函数为：

$$P(X=k) = (1-p)^{k-1}p$$

其中，$k$表示第一次成功所需的试验次数，$p$表示每次试验成功的概率。几何分布的期望和方差分别为：

$E(X) = \frac{1}{p}$

$Var(X) = \frac{1-p}{p^2}$

下面是几何分布的一些性质：

几何分布是离散的概率分布，它的取值为正整数。

几何分布是无记忆的，即它与之前的试验次数无关。这意味着，在某人射箭的例子中，如果他在第$k$次尝试中未命中，那么在接下来的尝试中，第一次命中目标的概率仍然为$p$，即使已经尝试了$k$次。

几何分布的期望随着$p$的增加而减小，方差随着$p$的增加而增大。当$p$接近0时，期望和方差都变得非常大。

几何分布可以用来描述一些场景，例如：

在一个制造过程中，每件产品有一定的概率出现缺陷，几何分布可以描述在检查多少件产品后第一次发现缺陷的概率。

在一场足球比赛中，射门球员每次射门得分的概率为$p$，几何分布可以描述第一次进球需要多少次射门的概率。

在一个在线广告投放系统中，某个广告被点击的概率为$p$，几何分布可以描述在多少次展示后第一次被点击的概率。

## 3.3.泊松分布

泊松分布是一种描述稀有事件发生次数的概率分布，通常用于描述在一段时间内某个事件发生的次数。例如，在一段时间内，电话接线员接到的电话数、邮局收到的邮件数、在高峰时间段内通过某个路口的车辆数等，都可能符合泊松分布。

泊松分布的概率质量函数为：

$$P(X=k) = \frac{\lambda^ke^{-\lambda}}{k!}$$

其中，$k$表示事件发生的次数，$\lambda$表示在单位时间内该事件平均发生的次数。泊松分布的期望和方差均为$\lambda$，即：

$$E(X) = \lambda,Var(X) =\lambda$$

下面是泊松分布的一些性质：

泊松分布是离散的概率分布，它的取值为非负整数。

泊松分布是无记忆的，即事件发生的次数与之前事件发生的时间无关。

当$\lambda$越大时，泊松分布越接近正态分布。

泊松分布可以用来描述一些场景，例如：

在一家医院急诊室，每小时平均有10名患者入院就诊，泊松分布可以描述在一个小时内入院就诊的患者数的概率分布。

在一家电视台的新闻部门，平均每天收到10篇新闻稿件，泊松分布可以描述在一天内收到新闻稿件数的概率分布。

在一家银行的某个自动取款机前，平均每分钟有3名用户使用该机器取款，泊松分布可以描述在一分钟内使用该取款机取款的用户数的概率分布。

## 3.4.超几何分布

$\quad$ 超几何分布是统计学上一种离散概率分布。它描述了由有限个对象中抽象，成功抽出$k$次指定种类的对象的概率(抽出不放回)。

$\quad$ 例如在有$N$个样本，其中$K$个是不及格的。超几何分布描述了在该$N$个样本中抽出$n$个，其中$k$个是不及格的个数。

$$f(k;n,K,N) = \frac{C_{K}^{k}C_{N-K}^{n-k}}{C_{N}^{n}}$$

$\quad$ 上式可如此理解：$C_{N}^{n}$ 表示所有在 $N$ 个样本中抽出$n$ 个方法数目。$C_{K}^{k}$ 表示在 $K$ 个样本中，抽出$k$个方法数目，即组合数，又称二项式系数。剩下的样本都是及格的，而及格的样本有$N-K$个，剩下的抽法有$C_{N-K}^{n-k}$ 。若$n=1$，超几何分布退化为伯努利分布。

$\quad$ 超几何分布的期望值为 $\frac{nK}{N}$ ，方差 $n\frac{K}{N}\frac{(N-K)}{N}\frac{N-n}{N-1}$

## 3.5.负二项分布

$\quad$ 负二项分布是统计学上的一种描述在一系列独立同分布的伯努利试验中，成功次数达到指定次数（记为$r$）时失败次数的离散概率分布。比如，如果我们定义掷骰子随机变量$x$的值为$x=1$时成功，$x  1$ 为失败，这时我们反复掷骰子直到1出现3次(成功次数$r=3$)，此时非1数字出现次数的概率分布为负二项分布。

$\quad$ 当$r$ 是整数的时候的负二项分布又称帕斯卡分布，其概率质量函数为：

$$f(k;r,p) = Pr(X=k) = C_{k + r - 1}^{r - 1}p^r(1-p)^k \quad for \quad k=0,1,2...$$

$\quad$ 其中$k$ 是失败的次数，$r$ 是成功的次数，$p$ 是事件成功的概率。在负二项分布的概率质量函数，由于$k + r$次伯努利试验为独立同分布，每个成功$r$，失败$k$次的事件的概率为$p^r(1-p)^{k}$。由于第$r$次成功一定是最后一次试验，所以应该在$k + r - 1$次试验中选择$r - 1$次成功，使用排列组合二项式系数获取所有可能的选择数。

负二项分布的期望是$\frac{r(1-p)}{p}$，方差为$\frac{r(1-p)}{p^2}$

# 4.连续随机变量分布

## 4.1.连续型均匀分布

$\quad$ 连续型均匀分布或矩形分布的随机变量$X$，在其值域内每个等长区间上取值的概率皆相等。其概率密度函数在该变量的值域内为常数。若$X$服从$[a,b]$上的均匀分布，则记作$X \sim U(a,b)$

$\quad$ 该分布的概率密度函数为：

$$f(x) = 
\begin{cases}
\frac{1}{b - a} , for \quad a \leq x \leq b \\ 
0 ,  elsewhere
\end{cases}$$

$\quad$ 累积分布函数为：

$$F(x) = 
\begin{cases}
0 , for \quad x < a \\ 
\frac{x - a}{b - a},for \quad a \leq x < b \\ 
1 , for \quad x \geq b
\end{cases}$$

$\quad$ 连续随机变量的期望值：

$$E[X] = \frac{a + b}{2}$$

$\quad$ 方差：

$$VAR[X] = \frac{(b - a)^2}{12}$$

## 4.2.指数分布

$\quad$ 指数分布表示独立随机事件发生的时间间隔。

$\quad$ 指数分布即形状参数$\alpha$为1的伽马分布。若随机变量$X$服从参数为 $\lambda $或$\beta$的指数分布,则记作：

$$X \sim Exp(\lambda) or X \sim Exp(\beta)$$

$\quad$ 两者意义相同，只是$\lambda$与$\beta$互为倒数关系。只要将以下式子做：$\lambda = \frac{1}{\beta}$即可。

$\quad$ 指数分布的概率密度函数为：

$$f(x;\lambda)=
\begin{cases}
\lambda e^{-\lambda x}, x \geq 0 \\
0, x <0 
\end{cases}$$

$\quad$ 累积分布函数为：

$$F(x;\lambda)=
\begin{cases}
1 - e^{-\lambda x}, x \geq 0 \\ 
0, x \geq 0.
\end{cases}$$

对于指数分布的期望值是

$$E(X) = \frac{1}{\lambda}$$

方差为：

$$Var(X) = \frac{1}{\lambda^2}$$

## 4.3.正态分布

正态分布也被称为高斯分布，正态分布的可能值为全体实数，参数为$\mu,\sigma^2$，表示为：$N(\mu,\sigma^2)$

$$f(x) = \frac{1}{\sqrt{2\pi} \sigma}\exp{(-\frac{(x - \mu)^2}{2\sigma^2})}, \quad x \in \mathbf{R}$$

正态分布的期望和方差为:

$$E(X) = \mu, Var(X) = \sigma^2$$

正态分布具有其他大多概率分布所不具备的性质，那就是将服从正态分布的随机变量$X$变成$aX+b$,其概率也会服从概率分布，变换后的期望和方差可以进行简单的计算：

$$aX+b \sim N(a\mu + b,a^2\sigma^2)$$

利用这个性质，$X \sim N(\mu,\sigma^2)$ 的标准化后的随机变量 $Z = \frac{(X - \mu)}{\sigma}$ 服从$N(0,1)$ 分布，被称为标准正态分布。

通常记标准正态变量为$Z (Z Score)$，记标准正态分布的概率密度函数为 $\phi(x)$ ，累计分布函数为 $\Phi(x)$，则有：

$$\phi(x) = \frac{1}{\sqrt{2}{\pi}}\exp{(-\frac{x^2}{2})}, x \in \mathbf{R}$$

$$\Phi(x) = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}{\exp{(-\frac{t^2}{2})}dt}$$

## 4.4.卡方分布

卡方分布，是概率论和统计学中常用的概率分布。k个独立的标准正态分布变量的平方和服从自由度为k的卡方分布。卡方分布为特殊的伽马分布，是统计推断中应用最为广泛的概率分布之一。

若$k$个随机变量 $Z_1,Z_2...Z_k$ 是相互独立且符合标准正态分布的随机变量，则随机变量$Z$的平方和。

$$X = \sum_{i=1}^{k}{Z_i^2}$$

被称为服从自由度为$k$的卡方分布，记作：

$$X \sim \chi^2(k)$$

$$X \sim \chi_k^2$$

卡方分布的概率密度函数为：

$$f_k(x) = \frac{1}{2^\frac{k}{2}\Gamma(\frac{k}{2})}x^{\frac{k}{2}-1}e^{\frac{-x}{2}}$$

其中 $x \geq 0 $,当 $x \leq 0$时候，$f_k(x) = 0$，这里的$\Gamma$代表Gamma函数

卡方分布的期望为$k$，方差为$2k$






